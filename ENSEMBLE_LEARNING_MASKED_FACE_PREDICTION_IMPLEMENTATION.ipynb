{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af75e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464b5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "import pathlib\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import  Conv2D, MaxPooling2D, Flatten, Dense,Dropout,BatchNormalization\n",
    "import tensorflow.keras \n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.utils as utils\n",
    "from tensorflow.keras.optimizers import Adam as adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad \n",
    "from tensorflow.keras.callbacks import  EarlyStopping ,ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import  Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6191cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.4.0\n",
      "TensorFlow version: 2.4.0\n",
      "Python version: 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a623c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths():\n",
    "    classes = []\n",
    "    for file in sorted(glob.iglob('lfw3/lfw3/lfw-deepfunneled_masked/*/')):\n",
    "        classes.append(file)\n",
    "    for i,d in enumerate(classes):\n",
    "        paths=d+'*.jpg'\n",
    "        class_=[]     \n",
    "        for file in sorted(glob.iglob(paths)):\n",
    "            class_.append(file)\n",
    "        classes[i]=class_ \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8597a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(classes):\n",
    "    allImages=[]\n",
    "    Labels = []\n",
    "    count = 0\n",
    "    for k,d in enumerate(classes[:]):\n",
    "        for i,sample in enumerate(d):\n",
    "            org_img = cv2.imread(sample)\n",
    "            #org_img = org_img.astype('float32')\n",
    "            org_img = cv2.resize(org_img, (224, 224))\n",
    "            # org_img=cv2.cvtColor(org_img,cv2.COLOR_BGR2RGB)\n",
    "            # np.append(allImages, org_img)\n",
    "            allImages.append(org_img)\n",
    "            Labels.append(count)\n",
    "        count = count + 1   \n",
    "    return np.array(allImages),np.array(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045b9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=get_paths()\n",
    "X,Y=get_all_images(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6270c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.05,shuffle=True, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b4e54",
   "metadata": {},
   "source": [
    "# Transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8742fa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# load the model\n",
    "def Transfer_FacenetModel_withNormlization():\n",
    "    facenetmodel = tf.keras.models.load_model('facenet_keras.h5',compile=False)\n",
    "    facenetmodel.load_weights(\"facenet_keras_weights.h5\")\n",
    "    for layer in facenetmodel.layers[:-50]:\n",
    "        layer.trainable = False\n",
    "    inputs = layers.Input(shape=(224,224,3))\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = facenetmodel(augmented)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    output_layer = Dense(5750, activation='softmax')(top_model)\n",
    "\n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62d3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Rescaling(scale=1./127.5, offset=-1),\n",
    "        layers.experimental.preprocessing.Resizing(160, 160),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe98cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Facenet1=Transfer_FacenetModel_withNormlization()\n",
    "Facenet1.load_weights('MyEn3facenet.h5')\n",
    "Facenet2=Transfer_FacenetModel_withNormlization()\n",
    "Facenet2.load_weights('MyEn4facenet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a31f9",
   "metadata": {},
   "source": [
    "# Transformer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ebbc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensamble Learning Training\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "projection_dim = 64\n",
    "\n",
    "num_heads = 8\n",
    "\n",
    "transformer_units = [\n",
    "\n",
    "    projection_dim * 2,\n",
    "\n",
    "    projection_dim,\n",
    "\n",
    "]  # Size of the transformer layers\n",
    "\n",
    "transformer_layers = 10\n",
    "\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d620c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccd84bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "\n",
    "    [\n",
    "\n",
    "        layers.experimental.preprocessing.Rescaling(1./255),\n",
    "\n",
    "        layers.experimental.preprocessing.Resizing(image_size, image_size),\n",
    "\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\")\n",
    "\n",
    "        #,layers.RandomRotation(0.3)\n",
    "\n",
    "    ],\n",
    "\n",
    "    name=\"data_augmentation\",\n",
    "\n",
    ")\n",
    "\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "\n",
    "#data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8402ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64859e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "\n",
    "    inputs = layers.Input(shape=(224,224,3))\n",
    "\n",
    "    # Augment data.\n",
    "\n",
    "    augmented = data_augmentation(inputs)\n",
    "\n",
    "    # Create patches.\n",
    "\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "\n",
    "    # Encode patches.\n",
    "\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "\n",
    "        # Layer normalization 1.\n",
    "\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.3\n",
    "\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "        # MLP.\n",
    "\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.3)\n",
    "\n",
    "        # Skip connection 2.\n",
    "\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    representation = layers.Flatten()(representation)\n",
    "\n",
    "    representation = layers.Dropout(0.6)(representation)\n",
    "\n",
    "    # Add MLP.\n",
    "\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.6)\n",
    "\n",
    "    # Classify outputs.\n",
    "\n",
    "    logits = layers.Dense(5750)(features)\n",
    "\n",
    "    # Create the Keras model.\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "512c6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38232450",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformerClassifier1 = create_vit_classifier()\n",
    "transformerClassifier2 = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "510a0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformerClassifier1.load_weights('FirstTransformer3Ensamble1.h5')\n",
    "transformerClassifier2.load_weights('FirstTransformer3Ensamble2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a241d1",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1e905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob1=Facenet1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b4c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob2=Facenet2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd36f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer12 = tf.keras.layers.Softmax()\n",
    "pred_prob3 = layer12(transformerClassifier1.predict(x_test)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1457a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob4 = layer12(transformerClassifier2.predict(x_test)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7dd57",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7496e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_model(predictions):\n",
    "    preds_classes = np.argmax(predictions, axis=-1)\n",
    "    accuracy = accuracy_score(y_test, preds_classes)\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f909fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Facenet 1: 80.30418250950571 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Facenet 1:\", evaluate_model(pred_prob1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2e5c559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Facenet 2: 79.08745247148289 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Facenet 2:\", evaluate_model(pred_prob2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8eab2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Tranformer 1: 69.04942965779468 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Tranformer 1:\", evaluate_model(pred_prob3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a47d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Tranformer 2: 68.59315589353612 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Tranformer 2:\", evaluate_model(pred_prob4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b141fc",
   "metadata": {},
   "source": [
    "# Ensemble Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a35f2",
   "metadata": {},
   "source": [
    "## Combining Facenet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "403e2ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Facenet ensemble: 87.9847908745247 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Facenet ensemble:\", evaluate_model(pred_prob1+pred_prob2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807e48f",
   "metadata": {},
   "source": [
    "## Combining Transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23a055f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Tranformer ensemble: 79.46768060836501 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Tranformer ensemble:\", evaluate_model(pred_prob3+pred_prob4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85101b8e",
   "metadata": {},
   "source": [
    "## Combining all models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "768c896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for complete ensemble: 92.01520912547528 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for complete ensemble:\", evaluate_model(pred_prob1+pred_prob2+pred_prob3+pred_prob4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c3f20",
   "metadata": {},
   "source": [
    "# Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "037b1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_weighted_ensemble(members, weights):\n",
    "    # make prediction\n",
    "    pred_probs = np.array(members)\n",
    "    # weighted sum across ensemble members\n",
    "    summed = np.tensordot(pred_probs, weights, axes=((0),(0)))\n",
    "    # evaluate model\n",
    "    score = evaluate_model(summed)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cabb9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to normalize a vector to have a unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = np.linalg.norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # else return normalized vector (unit norm)\n",
    "    return weights / result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "149ff00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for grid search weights\n",
    "from itertools import product\n",
    "def grid_search(members):\n",
    "    # weights to consider\n",
    "    w = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    best_score, best_weights = 0.0, None\n",
    "    # iterating all possible combinations using cartesian product\n",
    "    for weights in product(w, repeat=len(members)):\n",
    "        # skipping if all weights are equal (since already checked that case)\n",
    "        if len(set(weights)) == 1:\n",
    "            continue\n",
    "        # hacking normalize weight vector\n",
    "        weights = normalize(weights)\n",
    "        # evaluate weights\n",
    "        score = evaluate_weighted_ensemble(members, weights)\n",
    "        if score > best_score:\n",
    "            best_score, best_weights = score, weights\n",
    "            print(\"Current best weights: \", best_weights, \"with accuracy: \", best_score, \"%\")\n",
    "    return list(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b83c3",
   "metadata": {},
   "source": [
    "#### grid search weights\n",
    "members = [pred_prob1, pred_prob2, pred_prob3, pred_prob4]\n",
    "weights = grid_search(members)\n",
    "score = evaluate_weighted_ensemble(members, weights)\n",
    "print('Grid Search Best Weights: {}, Accuracy: {}%'.format(weights, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d40d2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_dataset(members):\n",
    "    stackX = None\n",
    "    for prediction in members:\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = prediction\n",
    "        else:\n",
    "            stackX = np.dstack((stackX, prediction))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb436c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model based on the outputs from the ensemble \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def fit_stacked_model(members, inputy):\n",
    " # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members)\n",
    " # fit standalone model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24483d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit stacked model using the ensemble\n",
    "model = fit_stacked_model(members, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cfb5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with the stacked model\n",
    "def stacked_prediction(members, model):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members)\n",
    "     # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "yhat = stacked_prediction(members, model)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "713f3d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Test Accuracy: 94.22053231939164%\n"
     ]
    }
   ],
   "source": [
    "print('Stacked Test Accuracy: {}%'.format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
